{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Models  <img src=\"https://imt-nord-europe.fr/wp-content/uploads/2021/08/cropped-IMT_Nord_Europe_.png\" alt=\"Drawing\" style=\"float: right; width: 150px;\"/>\n",
    "\n",
    "UV SDATA 2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Information\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. Fisher’s\n",
    "paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for\n",
    "example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of\n",
    "iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable\n",
    "from each other. The predicted attribute (the output) is the class of iris plant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "In this TP, you are supposed to play with different classification techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data visualisation\n",
    "    1. Show data using `seaborn.pairplot`.\n",
    "    1. T-distributed Stochastic Neighbor Embedding (t-SNE) is a machine learning algorithm for visualization. It can be used from `sklearn.manifold.TSNE`. Embed data (not label) into two dimension. Plot these points using their labels to color them. Change the perplexity parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dataset preprocessing\n",
    "    1. Make two numpy array $X$ and $y$, they contain respectively the set of feature vector and their label.\n",
    "    1. Map label to integer using `LabelEncoder` from `sklearn.preprocessing`. Now you got the set of feature vector and their corresponding true label !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement Linear Discriminant Analysis : we are going to implement LDA to the samples onto the new subspace, then we will use results to make prediction.\n",
    "    1. Compute the mean vector of each class :\n",
    "    $$\n",
    "    m_i = \\frac{1}{n_i} \\sum\\limits_{x \\in D_i}^{n} x_k,\n",
    "    $$\n",
    "    1. Compute the within-class scatter matrix :\n",
    "    $$\n",
    "    S_W = \\sum\\limits_{i=0}^{c} S_i,\n",
    "    $$\n",
    "    where $S_i = \\sum\\limits_{x \\in D_i}^{n} (x-m_i)(x-m_i)^T$.\n",
    "    1. Compute the between-class scatter matrix :\n",
    "    $$\n",
    "    S_B = \\sum\\limits_{x \\in D_i}^{n} (m_i-m)(m_i-m)^T,\n",
    "    $$\n",
    "    where $m$ is the overall mean, $m_i$ and $N_i$ are the sample mean and sizes of the respectives classes.\n",
    "    1. Solve the eigenvalue problem for the matrix $S_W^{-1}S_B$ using lineal from numpy.\n",
    "    1. Sort eigenvector by their eigenvalues from high to low.\n",
    "    1. Transform the samples onto the new subspace (by defaut the same number of dimension or a smaller given as parameter)\n",
    "    \n",
    "__Note that__: we do not compute the covariance matrix, it is easy to add a scaling\n",
    "factor to use the covariance matrix. However, the resulting eigenspace will be identical\n",
    "(identical eigenvectors, only the eigenvalues are scaled differently by a constant factor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compare your results with: `sklearn.discriminant analysis.LinearDiscriminantAnalysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define a function that predict the label of given set of feature vector :\n",
    "\\begin{align}\n",
    "    \\hat{C}_k & = argmax~C_k~p(C_k|x)\\\\\n",
    "    & = x^T \\Sigma^{-1} \\mu_k - \\frac{1}{2}\\mu_k^T \\Sigma^{-1} \\mu_k + log~p(x|C_k)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Predict the class of X and compare your results with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Assess your method on the iris dataset using cross-validation, (`from sklearn.model selection import train test split, StratifiedKFold`).\n",
    "    - Compute `f1_score`,\n",
    "    - Plot confusion matrix,\n",
    "    - $\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Plot results of the LDA transform with dim = 2, to display the regions of decision, you may use:\n",
    "```\n",
    "xx, yy = np.meshgrid(np.linspace(4, 8.5, 200), np.linspace(1.5, 4.5, 200))\n",
    "X_{grid} = np.c_[ xx.ravel(), yy.ravel()]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. QDA\n",
    "    1. Implement Quadratic Discriminant Analysis\n",
    "    1. Compare your results with `sklearn.discriminant analysis.QuadraticDiscriminantAnalysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__ that in this database, we do not have test data, so in order to validate the best classification technique (and the best parameters of the technique), we will use cross-validation techniques. Plot the samples in 2D or 3D so you get intuitions before applying the classification\n",
    "methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Information\n",
    "\n",
    "1. sepal length in cm\n",
    "1. sepal width in cm\n",
    "1. petal length in cm\n",
    "1. petal width in cm\n",
    "1. classes: Iris Setosa, Iris Versicolour, Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Fisher,R.A. “The use of multiple measurements in taxonomic problems” Annual Eugenics, 7,\n",
    "Part II, 179-188 (1936); also in “Contributions to Mathematical Statistics” (John Wiley, NY, 1950).\n",
    "\n",
    "[2] Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis. (Q327.D83) John\n",
    "Wiley & Sons. ISBN 0-471-22361-1. See page 218.\n",
    "\n",
    "[3] Dasarathy, B.V. (1980) “Nosing Around the Neighborhood: A New System Structure and\n",
    "Classification Rule for Recognition in Partially Exposed Environments”. IEEE Transactions on\n",
    "Pattern Analysis and Machine Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
    "\n",
    "[4] Gates, G.W. (1972) “The Reduced Nearest Neighbor Rule”. IEEE Transactions on Information\n",
    "Theory, May 1972, 431-433"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
